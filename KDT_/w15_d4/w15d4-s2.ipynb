{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad58f8c-0911-4158-9684-13fc46475caa",
   "metadata": {},
   "source": [
    "### 시도예정\n",
    "- 데이터 증식\n",
    "    - 좌우반전\n",
    "\n",
    "- 이전버전 G/D 믹스\n",
    "    - Save checkpoints of your models and mix in older versions of the generator and discriminator every couple of generations\n",
    "    \n",
    "    \n",
    "- Instead of using straight binary 0/1 for your discriminator target variable, add noise to the discriminator target variable\n",
    "\n",
    "- 드롭아웃 도입\n",
    "\n",
    "- Don't assume you have a good training schedule: check in on the norm of the gradient and visualize generated samples periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb63d944-fe7d-4737-9559-111030462f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99daba-a7db-4d04-931a-6c9a29a324fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        self.init_size = 4 # 원본 크기보다 16배 작은 값으로 초기화\n",
    "        self.layer1 = nn.Sequential(nn.Linear(latent_dim + n_classes, 512 * self.init_size * self.init_size)) # 초기 채널의 크기는 512 \n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(512), # 채널의 크기와 동일\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지\n",
    "            nn.BatchNorm2d(512, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 256으로\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 128로\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 64로\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 3으로\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 노이즈(noise) 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        inputs = torch.cat((noise, self.label_embed(labels)), -1)\n",
    "        output = self.layer1(inputs)\n",
    "        output = output.view(output.size(0), 512, self.init_size, self.init_size)\n",
    "        output = self.conv_blocks(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 판별자(Discriminator) 클래스 정의\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "\n",
    "        def make_block(in_channels, out_channels, bn=True):\n",
    "            # 하나의 블록(block)을 반복할 때마다 너비와 높이는 2배씩 감소\n",
    "            block = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)]\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            block.append(nn.Dropout2d(0.25))\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_channels, 0.8))\n",
    "            return block\n",
    "\n",
    "        # 너비와 높이가 32배씩 감소\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *make_block(2, 32, bn=False),\n",
    "            *make_block(32, 64),\n",
    "            *make_block(64, 128),\n",
    "            *make_block(128, 256),\n",
    "            *make_block(256, 512),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, 1 * 64 * 64)\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img, labels):\n",
    "        # 이미지 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        embed = self.label_embed(labels).view((img.size(0), 1, 64, 64))\n",
    "        inputs = torch.cat((img, embed), 1)\n",
    "        output = self.conv_blocks(inputs)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a6f804-d363-499a-a1ca-7fd6a036b770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "dcgan_generator = DCGANGenerator()\n",
    "dcgan_discriminator = DCGANDiscriminator()\n",
    "\n",
    "dcgan_generator.cuda()\n",
    "dcgan_discriminator.cuda()\n",
    "\n",
    "# 가중치(weights) 초기화\n",
    "dcgan_generator.apply(weights_init_normal)\n",
    "dcgan_discriminator.apply(weights_init_normal)\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.MSELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0001\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(dcgan_generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(dcgan_discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5bad6-8a6e-479c-9373-1d64310e12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400\n",
    "sample_interval = 500\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "        generated_labels = torch.randint(0, n_classes, (imgs.shape[0],)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = dcgan_generator(z, generated_labels)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(dcgan_discriminator(generated_imgs, generated_labels), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(dcgan_discriminator(real_imgs, labels), real)\n",
    "        fake_loss = adversarial_loss(dcgan_discriminator(generated_imgs.detach(), generated_labels), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(train_dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 클래스당 8개의 이미지를 생성하여 2 X 8 격자 이미지에 출력\n",
    "            z = torch.normal(mean=0, std=1, size=(n_classes * 8, latent_dim)).cuda()\n",
    "            labels = torch.LongTensor([i for i in range(n_classes) for _ in range(8)]).cuda()\n",
    "            generated_imgs = dcgan_generator(z, labels)\n",
    "            save_image(generated_imgs, f\"./results/dcgan/{done}.png\", nrow=8, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66d55f-ef9f-4c44-9825-92ea55da6496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07d08d-11f3-4376-b5d0-d927df439c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90328ffe-73ba-4169-80be-7ccc4d4411d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 수행\n",
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/custom/without_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/without_mask --batch-size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64760351-f71a-4b1e-bfc9-38b22461abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 수행\n",
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/custom/with_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/with_mask --batch-size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0624382e-8cf9-44da-9f0d-ea952440d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ./results/custom/ 폴더의 모든 파일을 results.zip라는 이름으로 압축\n",
    "!zip ./results.zip -r ./results/custom/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8d73e-618b-468c-a1e3-3e3c48696c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자(Generator) 클래스 정의\n",
    "class CustomGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomGenerator, self).__init__()\n",
    "        # 적절한 소스코드를 작성하세요.\n",
    "        pass\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 적절한 소스코드를 작성하세요.\n",
    "        pass\n",
    "\n",
    "\n",
    "# 판별자(Discriminator) 클래스 정의\n",
    "class CustomDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDiscriminator, self).__init__()\n",
    "        # 적절한 소스코드를 작성하세요.\n",
    "        pass\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img, labels):\n",
    "        # 적절한 소스코드를 작성하세요.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08328ed6-52c6-47c3-a994-8490e25a742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습하는 코드 작성하기\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
