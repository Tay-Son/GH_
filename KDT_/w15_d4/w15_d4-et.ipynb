{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6Cu6Wozwu72",
    "outputId": "fcfdacae-7f2e-4601-d59f-77ccf1a1d954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Face-Mask-Classification-20000-Dataset'...\n",
      "remote: Enumerating objects: 20017, done.\u001b[K\n",
      "remote: Total 20017 (delta 0), reused 0 (delta 0), pack-reused 20017\u001b[K\n",
      "Receiving objects: 100% (20017/20017), 600.78 MiB | 30.44 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n",
      "Checking out files: 100% (20001/20001), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ndb796/Face-Mask-Classification-20000-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7K_r_Qv_ruir"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67_-mDjCxMTW",
    "outputId": "467a1de9-12eb-47dc-d838-ddf480f85962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 18000\n",
      "Class names: ['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)) # normalization\n",
    "])\n",
    "\n",
    "data_dir = './Face-Mask-Classification-20000-Dataset/'\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "# print('Train dataset size:', len(train_dataset))\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "# print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kMgPSvFd2n6w"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        self.init_size = 4 # 원본 크기보다 16배 작은 값으로 초기화\n",
    "        self.layer1 = nn.Sequential(nn.Linear(latent_dim + n_classes, 512 * self.init_size * self.init_size)) # 초기 채널의 크기는 512 \n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(512), # 채널의 크기와 동일\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지\n",
    "            nn.BatchNorm2d(512, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 256으로\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 128로\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 64로\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 3으로\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 노이즈(noise) 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        inputs = torch.cat((noise, self.label_embed(labels)), -1)\n",
    "        output = self.layer1(inputs)\n",
    "        output = output.view(output.size(0), 512, self.init_size, self.init_size)\n",
    "        output = self.conv_blocks(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 판별자(Discriminator) 클래스 정의\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "\n",
    "        def make_block(in_channels, out_channels, bn=True):\n",
    "            # 하나의 블록(block)을 반복할 때마다 너비와 높이는 2배씩 감소\n",
    "            block = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)]\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            block.append(nn.Dropout2d(0.25))\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_channels, 0.8))\n",
    "            return block\n",
    "\n",
    "        # 너비와 높이가 32배씩 감소\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *make_block(2, 32, bn=False),\n",
    "            *make_block(32, 64),\n",
    "            *make_block(64, 128),\n",
    "            *make_block(128, 256),\n",
    "            *make_block(256, 512),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, 1 * 64 * 64)\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img, labels):\n",
    "        # 이미지 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        embed = self.label_embed(labels).view((img.size(0), 1, 64, 64))\n",
    "        inputs = torch.cat((img, embed), 1)\n",
    "        output = self.conv_blocks(inputs)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "clLAUAL53UNh"
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "dcgan_generator = DCGANGenerator()\n",
    "dcgan_discriminator = DCGANDiscriminator()\n",
    "\n",
    "dcgan_generator.cuda()\n",
    "dcgan_discriminator.cuda()\n",
    "\n",
    "# 가중치(weights) 초기화\n",
    "dcgan_generator.apply(weights_init_normal)\n",
    "dcgan_discriminator.apply(weights_init_normal)\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.MSELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0001\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(dcgan_generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(dcgan_discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5NHo7O6O3g47",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "630f8d71-2141-4560-d668-f61824f61ecc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/400] [D loss: 0.249] [G loss: 0.254] [Elapsed time: 88.51s]\n",
      "[Epoch 1/400] [D loss: 0.250] [G loss: 0.239] [Elapsed time: 176.87s]\n",
      "[Epoch 2/400] [D loss: 0.253] [G loss: 0.238] [Elapsed time: 265.15s]\n",
      "[Epoch 3/400] [D loss: 0.260] [G loss: 0.253] [Elapsed time: 353.49s]\n",
      "[Epoch 4/400] [D loss: 0.251] [G loss: 0.260] [Elapsed time: 441.79s]\n",
      "[Epoch 5/400] [D loss: 0.251] [G loss: 0.232] [Elapsed time: 530.09s]\n",
      "[Epoch 6/400] [D loss: 0.250] [G loss: 0.254] [Elapsed time: 618.39s]\n",
      "[Epoch 7/400] [D loss: 0.252] [G loss: 0.243] [Elapsed time: 706.75s]\n",
      "[Epoch 8/400] [D loss: 0.246] [G loss: 0.249] [Elapsed time: 795.09s]\n",
      "[Epoch 9/400] [D loss: 0.233] [G loss: 0.273] [Elapsed time: 883.38s]\n",
      "[Epoch 10/400] [D loss: 0.250] [G loss: 0.258] [Elapsed time: 971.75s]\n",
      "[Epoch 11/400] [D loss: 0.243] [G loss: 0.278] [Elapsed time: 1060.04s]\n",
      "[Epoch 12/400] [D loss: 0.236] [G loss: 0.272] [Elapsed time: 1148.43s]\n",
      "[Epoch 13/400] [D loss: 0.249] [G loss: 0.258] [Elapsed time: 1236.70s]\n",
      "[Epoch 14/400] [D loss: 0.248] [G loss: 0.262] [Elapsed time: 1325.04s]\n",
      "[Epoch 15/400] [D loss: 0.247] [G loss: 0.272] [Elapsed time: 1413.43s]\n",
      "[Epoch 16/400] [D loss: 0.234] [G loss: 0.253] [Elapsed time: 1501.73s]\n",
      "[Epoch 17/400] [D loss: 0.233] [G loss: 0.254] [Elapsed time: 1590.10s]\n",
      "[Epoch 18/400] [D loss: 0.249] [G loss: 0.299] [Elapsed time: 1678.37s]\n",
      "[Epoch 19/400] [D loss: 0.248] [G loss: 0.239] [Elapsed time: 1766.74s]\n",
      "[Epoch 20/400] [D loss: 0.241] [G loss: 0.227] [Elapsed time: 1855.07s]\n",
      "[Epoch 21/400] [D loss: 0.247] [G loss: 0.276] [Elapsed time: 1943.40s]\n",
      "[Epoch 22/400] [D loss: 0.259] [G loss: 0.264] [Elapsed time: 2031.67s]\n",
      "[Epoch 23/400] [D loss: 0.273] [G loss: 0.213] [Elapsed time: 2119.98s]\n",
      "[Epoch 24/400] [D loss: 0.229] [G loss: 0.241] [Elapsed time: 2208.35s]\n",
      "[Epoch 25/400] [D loss: 0.253] [G loss: 0.270] [Elapsed time: 2296.63s]\n",
      "[Epoch 26/400] [D loss: 0.252] [G loss: 0.246] [Elapsed time: 2384.97s]\n",
      "[Epoch 27/400] [D loss: 0.234] [G loss: 0.272] [Elapsed time: 2473.25s]\n",
      "[Epoch 28/400] [D loss: 0.272] [G loss: 0.243] [Elapsed time: 2561.61s]\n",
      "[Epoch 29/400] [D loss: 0.268] [G loss: 0.238] [Elapsed time: 2649.89s]\n",
      "[Epoch 30/400] [D loss: 0.271] [G loss: 0.223] [Elapsed time: 2738.17s]\n",
      "[Epoch 31/400] [D loss: 0.245] [G loss: 0.310] [Elapsed time: 2826.46s]\n",
      "[Epoch 32/400] [D loss: 0.263] [G loss: 0.260] [Elapsed time: 2914.74s]\n",
      "[Epoch 33/400] [D loss: 0.234] [G loss: 0.255] [Elapsed time: 3003.08s]\n",
      "[Epoch 34/400] [D loss: 0.235] [G loss: 0.269] [Elapsed time: 3091.32s]\n",
      "[Epoch 35/400] [D loss: 0.246] [G loss: 0.267] [Elapsed time: 3179.63s]\n",
      "[Epoch 36/400] [D loss: 0.258] [G loss: 0.290] [Elapsed time: 3267.93s]\n",
      "[Epoch 37/400] [D loss: 0.259] [G loss: 0.276] [Elapsed time: 3356.28s]\n",
      "[Epoch 38/400] [D loss: 0.261] [G loss: 0.229] [Elapsed time: 3444.59s]\n",
      "[Epoch 39/400] [D loss: 0.264] [G loss: 0.262] [Elapsed time: 3532.92s]\n",
      "[Epoch 40/400] [D loss: 0.232] [G loss: 0.252] [Elapsed time: 3621.24s]\n",
      "[Epoch 41/400] [D loss: 0.254] [G loss: 0.264] [Elapsed time: 3709.51s]\n",
      "[Epoch 42/400] [D loss: 0.260] [G loss: 0.239] [Elapsed time: 3797.83s]\n",
      "[Epoch 43/400] [D loss: 0.246] [G loss: 0.254] [Elapsed time: 3886.13s]\n",
      "[Epoch 44/400] [D loss: 0.253] [G loss: 0.232] [Elapsed time: 3974.47s]\n",
      "[Epoch 45/400] [D loss: 0.258] [G loss: 0.248] [Elapsed time: 4062.77s]\n",
      "[Epoch 46/400] [D loss: 0.284] [G loss: 0.244] [Elapsed time: 4151.08s]\n",
      "[Epoch 47/400] [D loss: 0.258] [G loss: 0.306] [Elapsed time: 4239.36s]\n",
      "[Epoch 48/400] [D loss: 0.243] [G loss: 0.257] [Elapsed time: 4327.59s]\n",
      "[Epoch 49/400] [D loss: 0.230] [G loss: 0.258] [Elapsed time: 4416.35s]\n",
      "[Epoch 50/400] [D loss: 0.261] [G loss: 0.326] [Elapsed time: 4505.21s]\n",
      "[Epoch 51/400] [D loss: 0.274] [G loss: 0.234] [Elapsed time: 4594.10s]\n",
      "[Epoch 52/400] [D loss: 0.239] [G loss: 0.275] [Elapsed time: 4682.47s]\n",
      "[Epoch 53/400] [D loss: 0.270] [G loss: 0.241] [Elapsed time: 4770.84s]\n",
      "[Epoch 54/400] [D loss: 0.236] [G loss: 0.244] [Elapsed time: 4859.15s]\n",
      "[Epoch 55/400] [D loss: 0.251] [G loss: 0.247] [Elapsed time: 4947.49s]\n",
      "[Epoch 56/400] [D loss: 0.245] [G loss: 0.321] [Elapsed time: 5035.94s]\n",
      "[Epoch 57/400] [D loss: 0.255] [G loss: 0.320] [Elapsed time: 5124.24s]\n",
      "[Epoch 58/400] [D loss: 0.259] [G loss: 0.276] [Elapsed time: 5212.56s]\n",
      "[Epoch 59/400] [D loss: 0.250] [G loss: 0.239] [Elapsed time: 5301.21s]\n",
      "[Epoch 60/400] [D loss: 0.221] [G loss: 0.282] [Elapsed time: 5389.61s]\n",
      "[Epoch 61/400] [D loss: 0.244] [G loss: 0.279] [Elapsed time: 5477.84s]\n",
      "[Epoch 62/400] [D loss: 0.241] [G loss: 0.313] [Elapsed time: 5566.15s]\n",
      "[Epoch 63/400] [D loss: 0.224] [G loss: 0.273] [Elapsed time: 5654.45s]\n",
      "[Epoch 64/400] [D loss: 0.231] [G loss: 0.323] [Elapsed time: 5742.71s]\n",
      "[Epoch 65/400] [D loss: 0.239] [G loss: 0.299] [Elapsed time: 5831.03s]\n",
      "[Epoch 66/400] [D loss: 0.261] [G loss: 0.305] [Elapsed time: 5919.28s]\n",
      "[Epoch 67/400] [D loss: 0.228] [G loss: 0.301] [Elapsed time: 6007.65s]\n",
      "[Epoch 68/400] [D loss: 0.238] [G loss: 0.271] [Elapsed time: 6095.95s]\n",
      "[Epoch 69/400] [D loss: 0.219] [G loss: 0.354] [Elapsed time: 6184.27s]\n",
      "[Epoch 70/400] [D loss: 0.237] [G loss: 0.211] [Elapsed time: 6272.69s]\n",
      "[Epoch 71/400] [D loss: 0.251] [G loss: 0.250] [Elapsed time: 6361.10s]\n",
      "[Epoch 72/400] [D loss: 0.269] [G loss: 0.254] [Elapsed time: 6449.42s]\n",
      "[Epoch 73/400] [D loss: 0.276] [G loss: 0.200] [Elapsed time: 6537.75s]\n",
      "[Epoch 74/400] [D loss: 0.237] [G loss: 0.250] [Elapsed time: 6626.46s]\n",
      "[Epoch 75/400] [D loss: 0.294] [G loss: 0.320] [Elapsed time: 6715.09s]\n",
      "[Epoch 76/400] [D loss: 0.260] [G loss: 0.240] [Elapsed time: 6803.84s]\n",
      "[Epoch 77/400] [D loss: 0.236] [G loss: 0.270] [Elapsed time: 6892.44s]\n",
      "[Epoch 78/400] [D loss: 0.251] [G loss: 0.254] [Elapsed time: 6981.12s]\n",
      "[Epoch 79/400] [D loss: 0.259] [G loss: 0.229] [Elapsed time: 7069.80s]\n",
      "[Epoch 80/400] [D loss: 0.257] [G loss: 0.245] [Elapsed time: 7158.43s]\n",
      "[Epoch 81/400] [D loss: 0.233] [G loss: 0.299] [Elapsed time: 7247.09s]\n",
      "[Epoch 82/400] [D loss: 0.238] [G loss: 0.227] [Elapsed time: 7335.71s]\n",
      "[Epoch 83/400] [D loss: 0.249] [G loss: 0.285] [Elapsed time: 7424.40s]\n",
      "[Epoch 84/400] [D loss: 0.236] [G loss: 0.259] [Elapsed time: 7513.07s]\n",
      "[Epoch 85/400] [D loss: 0.262] [G loss: 0.232] [Elapsed time: 7601.75s]\n",
      "[Epoch 86/400] [D loss: 0.220] [G loss: 0.308] [Elapsed time: 7690.44s]\n",
      "[Epoch 87/400] [D loss: 0.272] [G loss: 0.246] [Elapsed time: 7779.12s]\n",
      "[Epoch 88/400] [D loss: 0.216] [G loss: 0.253] [Elapsed time: 7867.79s]\n",
      "[Epoch 89/400] [D loss: 0.237] [G loss: 0.284] [Elapsed time: 7956.41s]\n",
      "[Epoch 90/400] [D loss: 0.233] [G loss: 0.286] [Elapsed time: 8045.09s]\n",
      "[Epoch 91/400] [D loss: 0.237] [G loss: 0.371] [Elapsed time: 8133.77s]\n",
      "[Epoch 92/400] [D loss: 0.240] [G loss: 0.199] [Elapsed time: 8222.42s]\n",
      "[Epoch 93/400] [D loss: 0.191] [G loss: 0.260] [Elapsed time: 8311.12s]\n",
      "[Epoch 94/400] [D loss: 0.272] [G loss: 0.271] [Elapsed time: 8399.81s]\n",
      "[Epoch 95/400] [D loss: 0.250] [G loss: 0.302] [Elapsed time: 8488.55s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./results/dcgan/\n",
    "\n",
    "n_epochs = 100 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 500 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "        generated_labels = torch.randint(0, n_classes, (imgs.shape[0],)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = dcgan_generator(z, generated_labels)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(dcgan_discriminator(generated_imgs, generated_labels), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(dcgan_discriminator(real_imgs, labels), real)\n",
    "        fake_loss = adversarial_loss(dcgan_discriminator(generated_imgs.detach(), generated_labels), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(train_dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 클래스당 8개의 이미지를 생성하여 2 X 8 격자 이미지에 출력\n",
    "            z = torch.normal(mean=0, std=1, size=(n_classes * 8, latent_dim)).cuda()\n",
    "            labels = torch.LongTensor([i for i in range(n_classes) for _ in range(8)]).cuda()\n",
    "            generated_imgs = dcgan_generator(z, labels)\n",
    "            save_image(generated_imgs, f\"./results/dcgan/{done}.png\", nrow=8, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.3f}] [G loss: {g_loss.item():.3f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPH2k4J3AfkZ"
   },
   "outputs": [],
   "source": [
    "# 모델 파라미터 저장\n",
    "torch.save(dcgan_generator.state_dict(), \"DCGAN_Generator_for_Face_Mask.pt\")\n",
    "torch.save(dcgan_discriminator.state_dict(), \"DCGAN_Discriminator_for_Face_Mask.pt\")\n",
    "# print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW5mD9maAmr9"
   },
   "outputs": [],
   "source": [
    "# 생성자(generator) 초기화\n",
    "dcgan_generator = DCGANGenerator()\n",
    "dcgan_generator.cuda()\n",
    "dcgan_generator.load_state_dict(torch.load(\"DCGAN_Generator_for_Face_Mask.pt\"))\n",
    "# dcgan_generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igeyTdy_gcen"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/hukkelas/pytorch-frechet-inception-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjrEpHSxYH_k"
   },
   "outputs": [],
   "source": [
    "!mkdir -p ./results/dcgan/with_mask\n",
    "!mkdir -p ./results/dcgan/without_mask\n",
    "\n",
    "from IPython.display import Image as Display\n",
    "\n",
    "\n",
    "# 마스크를 착용한 총 10 * 100개의 얼굴 이미지를 생성\n",
    "for i in range(10):\n",
    "    # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
    "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
    "    generated_labels = torch.cuda.IntTensor(100).fill_(0)\n",
    "    # 이미지 생성\n",
    "    generated_imgs = dcgan_generator(z, generated_labels)\n",
    "\n",
    "    for j in range(100):\n",
    "        save_image(generated_imgs.data[j], f'./results/dcgan/with_mask/{i * 100 + j}.png', normalize=True)\n",
    "\n",
    "\n",
    "# 마스크를 착용한 총 10 * 100개의 얼굴 이미지를 생성\n",
    "for i in range(10):\n",
    "    # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
    "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
    "    generated_labels = torch.cuda.IntTensor(100).fill_(1)\n",
    "    # 이미지 생성\n",
    "    generated_imgs = dcgan_generator(z, generated_labels)\n",
    "\n",
    "    for j in range(100):\n",
    "        save_image(generated_imgs.data[j], f'./results/dcgan/without_mask/{i * 100 + j}.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oS7igDGQKWPE"
   },
   "outputs": [],
   "source": [
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/dcgan/without_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/without_mask --batch-size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRfnIr-SiteR"
   },
   "outputs": [],
   "source": [
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/dcgan/with_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/with_mask --batch-size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqwVe5mv87MB"
   },
   "outputs": [],
   "source": [
    "# ./results/custom/ 폴더의 모든 파일을 results.zip라는 이름으로 압축\n",
    "!zip ./results.zip -r ./results/custom/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zz8k4L9a9cKk"
   },
   "outputs": [],
   "source": [
    "# Google Colab으로부터 results.zip 압축 파일 다운로드\n",
    "from google.colab import files\n",
    "\n",
    "files.download('./results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhXhKvS-Nvf1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "w14d4-s0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
