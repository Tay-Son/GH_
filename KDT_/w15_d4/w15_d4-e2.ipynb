{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7K_r_Qv_ruir"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67_-mDjCxMTW",
    "outputId": "467a1de9-12eb-47dc-d838-ddf480f85962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 40000\n",
      "Class names: ['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Grayscale(1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5)) # normalization\n",
    "])\n",
    "\n",
    "data_dir = './Face-Mask-Classification-20000-Dataset-v2/'\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir), transforms_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "print('Train dataset size:', len(train_dataset))\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kMgPSvFd2n6w"
   },
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "n_classes = 2\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class DCGANGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, n_classes)\n",
    "\n",
    "        self.init_size = 4 # 원본 크기보다 16배 작은 값으로 초기화\n",
    "        self.layer1 = nn.Sequential(nn.Linear(latent_dim + n_classes, 512 * self.init_size * self.init_size)) # 초기 채널의 크기는 512 \n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(512), # 채널의 크기와 동일\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지\n",
    "            nn.BatchNorm2d(512, 0.8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 256으로\n",
    "            nn.BatchNorm2d(256, 0.8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 128로\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Upsample(scale_factor=2), # 너비와 높이 2배씩 증가\n",
    "            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 64로\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1), # 너비와 높이 유지, 채널의 크기는 3으로\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, labels):\n",
    "        # 노이즈(noise) 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        inputs = torch.cat((noise, self.label_embed(labels)), -1)\n",
    "        output = self.layer1(inputs)\n",
    "        output = output.view(output.size(0), 512, self.init_size, self.init_size)\n",
    "        output = self.conv_blocks(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 판별자(Discriminator) 클래스 정의\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "\n",
    "        def make_block(in_channels, out_channels, bn=True):\n",
    "            # 하나의 블록(block)을 반복할 때마다 너비와 높이는 2배씩 감소\n",
    "            block = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)]\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            block.append(nn.Dropout2d(0.25))\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_channels, 0.8))\n",
    "            return block\n",
    "\n",
    "        # 너비와 높이가 32배씩 감소\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *make_block(2, 32, bn=False),\n",
    "            *make_block(32, 64),\n",
    "            *make_block(64, 128),\n",
    "            *make_block(128, 256),\n",
    "            *make_block(256, 512),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2 * 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 레이블 정보를 임베딩 차원으로 매핑하여 사용\n",
    "        self.label_embed = nn.Embedding(n_classes, 1 * 64 * 64)\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img, labels):\n",
    "        # 이미지 벡터와 레이블 임베딩을 순차적으로 연결하여 입력\n",
    "        embed = self.label_embed(labels).view((img.size(0), 1, 64, 64))\n",
    "        inputs = torch.cat((img, embed), 1)\n",
    "        output = self.conv_blocks(inputs)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "clLAUAL53UNh"
   },
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "dcgan_generator = DCGANGenerator()\n",
    "dcgan_discriminator = DCGANDiscriminator()\n",
    "\n",
    "dcgan_generator.cuda()\n",
    "dcgan_discriminator.cuda()\n",
    "\n",
    "# 가중치(weights) 초기화\n",
    "dcgan_generator.apply(weights_init_normal)\n",
    "dcgan_discriminator.apply(weights_init_normal)\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "adversarial_loss = nn.MSELoss()\n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0001\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(dcgan_generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(dcgan_discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NHo7O6O3g47",
    "outputId": "630f8d71-2141-4560-d668-f61824f61ecc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [D loss: 0.258] [G loss: 0.301] [Elapsed time: 54.79s]\n",
      "[Epoch 1/50] [D loss: 0.233] [G loss: 0.281] [Elapsed time: 109.54s]\n",
      "[Epoch 2/50] [D loss: 0.209] [G loss: 0.234] [Elapsed time: 164.41s]\n",
      "[Epoch 3/50] [D loss: 0.209] [G loss: 0.276] [Elapsed time: 219.39s]\n",
      "[Epoch 4/50] [D loss: 0.240] [G loss: 0.146] [Elapsed time: 274.00s]\n",
      "[Epoch 5/50] [D loss: 0.177] [G loss: 0.295] [Elapsed time: 328.56s]\n",
      "[Epoch 6/50] [D loss: 0.269] [G loss: 0.376] [Elapsed time: 383.65s]\n",
      "[Epoch 7/50] [D loss: 0.179] [G loss: 0.178] [Elapsed time: 438.09s]\n",
      "[Epoch 8/50] [D loss: 0.203] [G loss: 0.230] [Elapsed time: 492.80s]\n",
      "[Epoch 9/50] [D loss: 0.245] [G loss: 0.360] [Elapsed time: 547.43s]\n",
      "[Epoch 10/50] [D loss: 0.240] [G loss: 0.421] [Elapsed time: 602.79s]\n",
      "[Epoch 11/50] [D loss: 0.213] [G loss: 0.317] [Elapsed time: 658.19s]\n",
      "[Epoch 12/50] [D loss: 0.249] [G loss: 0.246] [Elapsed time: 712.71s]\n",
      "[Epoch 13/50] [D loss: 0.230] [G loss: 0.205] [Elapsed time: 767.85s]\n",
      "[Epoch 14/50] [D loss: 0.191] [G loss: 0.414] [Elapsed time: 822.44s]\n",
      "[Epoch 15/50] [D loss: 0.180] [G loss: 0.425] [Elapsed time: 877.07s]\n",
      "[Epoch 16/50] [D loss: 0.223] [G loss: 0.250] [Elapsed time: 931.47s]\n",
      "[Epoch 17/50] [D loss: 0.236] [G loss: 0.401] [Elapsed time: 986.38s]\n",
      "[Epoch 18/50] [D loss: 0.169] [G loss: 0.415] [Elapsed time: 1040.92s]\n",
      "[Epoch 19/50] [D loss: 0.230] [G loss: 0.329] [Elapsed time: 1096.00s]\n",
      "[Epoch 20/50] [D loss: 0.292] [G loss: 0.493] [Elapsed time: 1151.20s]\n",
      "[Epoch 21/50] [D loss: 0.180] [G loss: 0.231] [Elapsed time: 1206.00s]\n",
      "[Epoch 22/50] [D loss: 0.227] [G loss: 0.382] [Elapsed time: 1260.04s]\n",
      "[Epoch 23/50] [D loss: 0.284] [G loss: 0.354] [Elapsed time: 1315.16s]\n",
      "[Epoch 24/50] [D loss: 0.228] [G loss: 0.349] [Elapsed time: 1369.47s]\n",
      "[Epoch 25/50] [D loss: 0.215] [G loss: 0.361] [Elapsed time: 1423.57s]\n",
      "[Epoch 26/50] [D loss: 0.240] [G loss: 0.162] [Elapsed time: 1477.93s]\n",
      "[Epoch 27/50] [D loss: 0.247] [G loss: 0.374] [Elapsed time: 1532.90s]\n",
      "[Epoch 28/50] [D loss: 0.260] [G loss: 0.370] [Elapsed time: 1587.41s]\n",
      "[Epoch 29/50] [D loss: 0.259] [G loss: 0.420] [Elapsed time: 1641.93s]\n",
      "[Epoch 30/50] [D loss: 0.204] [G loss: 0.298] [Elapsed time: 1696.35s]\n",
      "[Epoch 31/50] [D loss: 0.201] [G loss: 0.336] [Elapsed time: 1751.19s]\n",
      "[Epoch 32/50] [D loss: 0.186] [G loss: 0.374] [Elapsed time: 1806.56s]\n",
      "[Epoch 33/50] [D loss: 0.222] [G loss: 0.373] [Elapsed time: 1863.05s]\n",
      "[Epoch 34/50] [D loss: 0.265] [G loss: 0.186] [Elapsed time: 1920.67s]\n",
      "[Epoch 35/50] [D loss: 0.182] [G loss: 0.323] [Elapsed time: 1976.41s]\n",
      "[Epoch 36/50] [D loss: 0.162] [G loss: 0.418] [Elapsed time: 2032.77s]\n",
      "[Epoch 37/50] [D loss: 0.241] [G loss: 0.152] [Elapsed time: 2088.35s]\n",
      "[Epoch 38/50] [D loss: 0.264] [G loss: 0.256] [Elapsed time: 2142.70s]\n",
      "[Epoch 39/50] [D loss: 0.223] [G loss: 0.355] [Elapsed time: 2197.24s]\n",
      "[Epoch 40/50] [D loss: 0.262] [G loss: 0.302] [Elapsed time: 2251.90s]\n",
      "[Epoch 41/50] [D loss: 0.191] [G loss: 0.251] [Elapsed time: 2306.57s]\n",
      "[Epoch 42/50] [D loss: 0.169] [G loss: 0.347] [Elapsed time: 2361.17s]\n",
      "[Epoch 43/50] [D loss: 0.204] [G loss: 0.377] [Elapsed time: 2415.99s]\n",
      "[Epoch 44/50] [D loss: 0.143] [G loss: 0.369] [Elapsed time: 2470.57s]\n",
      "[Epoch 45/50] [D loss: 0.335] [G loss: 0.377] [Elapsed time: 2525.34s]\n",
      "[Epoch 46/50] [D loss: 0.213] [G loss: 0.226] [Elapsed time: 2579.84s]\n",
      "[Epoch 47/50] [D loss: 0.174] [G loss: 0.268] [Elapsed time: 2633.86s]\n",
      "[Epoch 48/50] [D loss: 0.239] [G loss: 0.371] [Elapsed time: 2688.45s]\n",
      "[Epoch 49/50] [D loss: 0.215] [G loss: 0.352] [Elapsed time: 2742.76s]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 500 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.shape[0], 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 및 랜덤 레이블(label) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "        generated_labels = torch.randint(0, n_classes, (imgs.shape[0],)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = dcgan_generator(z, generated_labels)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(dcgan_discriminator(generated_imgs, generated_labels), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(dcgan_discriminator(real_imgs, labels), real)\n",
    "        fake_loss = adversarial_loss(dcgan_discriminator(generated_imgs.detach(), generated_labels), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(train_dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 클래스당 8개의 이미지를 생성하여 2 X 8 격자 이미지에 출력\n",
    "            z = torch.normal(mean=0, std=1, size=(n_classes * 8, latent_dim)).cuda()\n",
    "            labels = torch.LongTensor([i for i in range(n_classes) for _ in range(8)]).cuda()\n",
    "            generated_imgs = dcgan_generator(z, labels)\n",
    "            save_image(generated_imgs, f\"./results/dcgan/{done}.png\", nrow=8, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.3f}] [G loss: {g_loss.item():.3f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "sPH2k4J3AfkZ"
   },
   "outputs": [],
   "source": [
    "torch.save(dcgan_generator.state_dict(), \"DCGAN-e2-e050-G.pt\")\n",
    "torch.save(dcgan_discriminator.state_dict(), \"DCGAN-e2-e050-D.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "KjrEpHSxYH_k"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as Display\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
    "    generated_labels = torch.cuda.IntTensor(100).fill_(0)\n",
    "    generated_imgs = dcgan_generator(z, generated_labels)\n",
    "    for j in range(100):\n",
    "        save_image(generated_imgs.data[j], f'./results/dcgan/with_mask/{i * 100 + j}.png', normalize=True)\n",
    "\n",
    "for i in range(10):\n",
    "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
    "    generated_labels = torch.cuda.IntTensor(100).fill_(1)\n",
    "    generated_imgs = dcgan_generator(z, generated_labels)\n",
    "    for j in range(100):\n",
    "        save_image(generated_imgs.data[j], f'./results/dcgan/without_mask/{i * 100 + j}.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "oS7igDGQKWPE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141.40431116712435\n"
     ]
    }
   ],
   "source": [
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/dcgan/without_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/without_mask --batch-size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jRfnIr-SiteR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.97720975340359\n"
     ]
    }
   ],
   "source": [
    "!python ./pytorch-frechet-inception-distance/fid.py --path1 ./results/dcgan/with_mask --path2 ./Face-Mask-Classification-20000-Dataset/test/with_mask --batch-size 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqwVe5mv87MB"
   },
   "outputs": [],
   "source": [
    "# ./results/custom/ 폴더의 모든 파일을 results.zip라는 이름으로 압축\n",
    "!zip ./results.zip -r ./results/custom/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zz8k4L9a9cKk"
   },
   "outputs": [],
   "source": [
    "# Google Colab으로부터 results.zip 압축 파일 다운로드\n",
    "from google.colab import files\n",
    "\n",
    "files.download('./results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhXhKvS-Nvf1"
   },
   "source": [
    "- e050\n",
    "- e100\n",
    "- e150\n",
    "- \n",
    "- 149 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "w14d4-s0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
